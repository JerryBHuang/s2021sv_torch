{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d501e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import save \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de47b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53860171",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c64dd265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((891, 13), (418, 13))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"./data/train.csv\")\n",
    "# train_df = pd.read_csv(\"./data/train.csv\").loc[0:800]\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "train_df = train_df[[\"PassengerId\", \"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Embarked\", \"Parch\", \"Fare\"]]  \n",
    "for index, x in train_df.iterrows():\n",
    "    x[\"SibSp\"] = \"s\" + str(x[\"SibSp\"])\n",
    "\n",
    "train_df = train_df.fillna({\"Embarked\":\"Q\", \"Age\": 0})\n",
    "train_df = pd.get_dummies(train_df) # 独热编码，也可以二值化\n",
    "Pclass_1,Pclass_2,Pclass_3 = [],[],[]\n",
    "\n",
    "for index, line in train_df.iterrows():\n",
    "    if line[\"Pclass\"] == 1.0:\n",
    "        Pclass_1.append(1)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(0)\n",
    "    elif line[\"Pclass\"] == 2.0:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(1)\n",
    "        Pclass_3.append(0)\n",
    "    else:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(1)\n",
    "    \n",
    "        \n",
    "train_df[\"Pclass_1\"], train_df[\"Pclass_2\"], train_df[\"Pclass_3\"] = Pclass_1, Pclass_2, Pclass_3\n",
    "\n",
    "\n",
    "# train_df['SibSp_1'] = np.array(train_df['SibSp'] == 1).astype(np.int32)\n",
    "# train_df['SibSp_0'] = np.array(train_df['SibSp'] == 0).astype(np.int32)\n",
    "# train_df['SibSp_2'] = np.array(train_df['SibSp'] == 2).astype(np.int32)\n",
    "# train_df['SibSp_3'] = np.array(train_df['SibSp'] == 3).astype(np.int32)\n",
    "# train_df['SibSp_4'] = np.array(train_df['SibSp'] == 4).astype(np.int32)\n",
    "# train_df['SibSp_6'] = np.array(train_df['SibSp'] == 6).astype(np.int32)\n",
    "# train_df['SibSp_8'] = np.array(train_df['SibSp'] == 8).astype(np.int32)\n",
    "# train_df.drop(\"SibSp\", axis=1)\n",
    "\n",
    "\n",
    "# test_df = pd.read_csv(\"./data/train.csv\").loc[800:]\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "test_df  = test_df[[\"PassengerId\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Embarked\", \"Parch\", \"Fare\"]]\n",
    "test_df = test_df.fillna({\"Embarked\":\"C\", \"Age\": 0})\n",
    "test_df = pd.get_dummies(test_df)\n",
    "Pclass_1,Pclass_2,Pclass_3 = [],[],[]\n",
    "for index, line in test_df.iterrows():\n",
    "    if line[\"Pclass\"] == 1.0:\n",
    "        Pclass_1.append(1)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(0)\n",
    "    elif line[\"Pclass\"] == 2.0:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(1)\n",
    "        Pclass_3.append(0)\n",
    "    else:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(1)\n",
    "test_df[\"Pclass_1\"], test_df[\"Pclass_2\"], test_df[\"Pclass_3\"] = Pclass_1, Pclass_2, Pclass_3\n",
    "\n",
    "\n",
    "# test_df['SibSp_1'] = np.array(test_df['SibSp'] == 1).astype(np.int32)\n",
    "# test_df['SibSp_0'] = np.array(test_df['SibSp'] == 0).astype(np.int32)\n",
    "# test_df['SibSp_2'] = np.array(test_df['SibSp'] == 2).astype(np.int32)\n",
    "# test_df['SibSp_3'] = np.array(test_df['SibSp'] == 3).astype(np.int32)\n",
    "# test_df['SibSp_4'] = np.array(test_df['SibSp'] == 4).astype(np.int32)\n",
    "# test_df['SibSp_6'] = np.array(test_df['SibSp'] == 6).astype(np.int32)\n",
    "# test_df['SibSp_8'] = np.array(test_df['SibSp'] == 8).astype(np.int32)\n",
    "# test_df.drop(\"SibSp\", axis=1)\n",
    "\n",
    "\n",
    "labels = np.array(train_df['Survived'], dtype=np.float32)\n",
    "#labels = np.array(train_df['Survived'], dtype=np.float32)\n",
    "new_labels = []\n",
    "for i in labels:\n",
    "    # 死亡 活着\n",
    "    #  1    0\n",
    "    #  0    1\n",
    "    \n",
    "    if i==1: \n",
    "        new_labels.append([0, 1])\n",
    "    else:\n",
    "        new_labels.append([1, 0])\n",
    "labels = np.array(new_labels)\n",
    "print(labels)\n",
    "# train_df = train_df.drop(columns=[\"Survived\", \"Pclass\",\"SibSp\",],) \n",
    "train_df = train_df.drop(columns=[\"Survived\", \"Pclass\",],) \n",
    "# test_df = test_df.drop(columns=[\"Pclass\",\"SibSp\",],)\n",
    "test_df = test_df.drop(columns=[\"Pclass\",],)\n",
    "train_features = np.array(StandardScaler().fit_transform(train_df), dtype=np.float32)\n",
    "test_features = np.array(StandardScaler().fit_transform(test_df), dtype=np.float32)\n",
    "# test_features = np.array(test_df, dtype=np.float32)\n",
    "# train_features = np.array(train_df, dtype=np.float32)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa6a98",
   "metadata": {},
   "source": [
    "### 定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53d332e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "input_size = train_features.shape[1]\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 7)\n",
    "#         self.hidden1 = nn.Linear(8, 4)\n",
    "#         self.hidden2 = nn.Linear(256, 80)\n",
    "        self.out = nn.Linear(7, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "#         x = F.relu(self.hidden1(x))\n",
    "#         x = F.relu(self.hidden2(x))\n",
    "       # x = F.relu(self.hidden3(x))\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "    \n",
    "net = LinearRegressionModel()   \n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019d74b",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "928e2015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jerry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\jerry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "num_epochs = 1000\n",
    "train_features = torch.tensor(train_features, dtype=torch.float)\n",
    "labels = torch.tensor(labels, dtype=torch.float)\n",
    "train_ds = TensorDataset(train_features, labels)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True) # MINI-Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50640c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:0.03405700996518135 correct:8 acc:10.666666666666668%\n",
      "epoch:25 loss:0.07722539454698563 correct:6 acc:8.0%\n",
      "epoch:50 loss:0.26206961274147034 correct:9 acc:12.0%\n",
      "epoch:75 loss:0.12442474812269211 correct:8 acc:10.666666666666668%\n",
      "epoch:100 loss:0.010081815533339977 correct:7 acc:9.333333333333334%\n",
      "epoch:125 loss:0.4681619703769684 correct:6 acc:8.0%\n",
      "epoch:150 loss:0.023560017347335815 correct:5 acc:6.666666666666667%\n",
      "epoch:175 loss:0.004121491685509682 correct:10 acc:13.333333333333334%\n",
      "epoch:200 loss:0.05554385110735893 correct:8 acc:10.666666666666668%\n",
      "epoch:225 loss:0.07921872287988663 correct:5 acc:6.666666666666667%\n",
      "epoch:250 loss:0.25026562809944153 correct:9 acc:12.0%\n",
      "epoch:275 loss:0.14298667013645172 correct:9 acc:12.0%\n",
      "epoch:300 loss:0.005576417315751314 correct:9 acc:12.0%\n",
      "epoch:325 loss:0.10616409778594971 correct:8 acc:10.666666666666668%\n",
      "epoch:350 loss:0.2021588832139969 correct:4 acc:5.333333333333334%\n",
      "epoch:375 loss:0.013818356208503246 correct:14 acc:18.666666666666668%\n",
      "epoch:400 loss:0.3100970387458801 correct:11 acc:14.666666666666666%\n",
      "epoch:425 loss:0.01814928464591503 correct:12 acc:16.0%\n",
      "epoch:450 loss:0.21647419035434723 correct:10 acc:13.333333333333334%\n",
      "epoch:475 loss:0.0030544374603778124 correct:12 acc:16.0%\n",
      "epoch:500 loss:0.011897311545908451 correct:13 acc:17.333333333333336%\n",
      "epoch:525 loss:0.14686480164527893 correct:10 acc:13.333333333333334%\n",
      "epoch:550 loss:0.07571961730718613 correct:9 acc:12.0%\n",
      "epoch:575 loss:0.4651053845882416 correct:8 acc:10.666666666666668%\n",
      "epoch:600 loss:0.41937556862831116 correct:9 acc:12.0%\n",
      "epoch:625 loss:0.009216724894940853 correct:10 acc:13.333333333333334%\n",
      "epoch:650 loss:0.14868615567684174 correct:4 acc:5.333333333333334%\n",
      "epoch:675 loss:0.2132088989019394 correct:10 acc:13.333333333333334%\n",
      "epoch:700 loss:0.09484786540269852 correct:10 acc:13.333333333333334%\n",
      "epoch:725 loss:0.1170862540602684 correct:10 acc:13.333333333333334%\n",
      "epoch:750 loss:0.05722920596599579 correct:8 acc:10.666666666666668%\n",
      "epoch:775 loss:0.004739637952297926 correct:9 acc:12.0%\n",
      "epoch:800 loss:0.35816046595573425 correct:10 acc:13.333333333333334%\n",
      "epoch:825 loss:0.03145318105816841 correct:10 acc:13.333333333333334%\n",
      "epoch:850 loss:0.03134141117334366 correct:14 acc:18.666666666666668%\n",
      "epoch:875 loss:0.08502858132123947 correct:13 acc:17.333333333333336%\n",
      "epoch:900 loss:0.019516393542289734 correct:13 acc:17.333333333333336%\n",
      "epoch:925 loss:0.05582703277468681 correct:7 acc:9.333333333333334%\n",
      "epoch:950 loss:0.053968023508787155 correct:10 acc:13.333333333333334%\n",
      "epoch:975 loss:0.028823748230934143 correct:10 acc:13.333333333333334%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "best_model_wts = net.state_dict()\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    \n",
    "    total = 0\n",
    "    corrects = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        total +=1\n",
    "        optimizer.zero_grad()\n",
    "        #print(x_batch.shape[1])\n",
    "        outputs = net(x_batch)\n",
    "        answer_ls = list()\n",
    "        for a, b in outputs:\n",
    "            if a>b:\n",
    "                answer_ls.append([1, 0])\n",
    "            else:\n",
    "                answer_ls.append([0, 1])\n",
    "        if torch.tensor(answer_ls, dtype=torch.float).equal(y_batch):\n",
    "            corrects += 1\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    acc = corrects/total*100\n",
    "    if acc > best_acc:\n",
    "        best_model_wts = copy.deepcopy(net.state_dict())\n",
    "        best_acc = acc\n",
    "    if epoch%25==0:\n",
    "        print(\"epoch:{} loss:{} correct:{} acc:{}%\".format(epoch, loss.item(), corrects, corrects/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ab5e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jerry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.27721661054994"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#print(\"test features\", test_features)\n",
    "net.load_state_dict(best_model_wts)\n",
    "train_arr = np.array(train_features, dtype=np.float)\n",
    "tensors = torch.tensor(train_arr, dtype=torch.float32)\n",
    "\n",
    "outputs = net(tensors).data.numpy()\n",
    "ans = []\n",
    "for a, b in outputs:\n",
    "    if a>b:\n",
    "        ans.append(1)\n",
    "    else:\n",
    "        ans.append(0)\n",
    "answer = np.array(ans).tolist()\n",
    "\n",
    "        \n",
    "lab = []\n",
    "labels = np.array(labels).tolist()\n",
    "for a, b in labels:\n",
    "    if a==1:\n",
    "        \n",
    "        lab.append(1)\n",
    "    else:\n",
    "        lab.append(0)        \n",
    "length = len(ans)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "print(lab)\n",
    "print(ans)\n",
    "for a in range(length):\n",
    "    if lab[a] == answer[a]:\n",
    "        correct+=1\n",
    "\n",
    "correct/length*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "676dfbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.from_numpy(test_features)\n",
    "predict = net(test_data)\n",
    "outputs = predict.data.numpy()\n",
    "answer_ls = []\n",
    "for a, b in outputs:\n",
    "    if a>b:\n",
    "        answer_ls.append([1, 0])\n",
    "    else:\n",
    "        answer_ls.append([0, 1])\n",
    "lab = []\n",
    "for a, b in answer_ls:\n",
    "    if a==1:\n",
    "        lab.append(0)\n",
    "    else:\n",
    "        lab.append(1)          \n",
    "outputs = np.array(lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48e3b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "    \"PassengerId\": np.array(range(892, 1310)),\n",
    "    \"Survived\": outputs\n",
    "})\n",
    "dataframe.to_csv(\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c4d01ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jerry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42980343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8ba8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
