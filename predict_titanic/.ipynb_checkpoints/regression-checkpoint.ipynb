{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72d501e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import save \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de47b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53860171",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c64dd265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_6</th>\n",
       "      <th>SibSp_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>797</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>801</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0              1       3  22.0      1      0   7.2500           0         1   \n",
       "1              2       1  38.0      1      0  71.2833           1         0   \n",
       "2              3       3  26.0      0      0   7.9250           1         0   \n",
       "3              4       1  35.0      1      0  53.1000           1         0   \n",
       "4              5       3  35.0      0      0   8.0500           0         1   \n",
       "..           ...     ...   ...    ...    ...      ...         ...       ...   \n",
       "796          797       1  49.0      0      0  25.9292           1         0   \n",
       "797          798       3  31.0      0      0   8.6833           1         0   \n",
       "798          799       3  30.0      0      0   7.2292           0         1   \n",
       "799          800       3  30.0      1      1  24.1500           1         0   \n",
       "800          801       2  34.0      0      0  13.0000           0         1   \n",
       "\n",
       "     Embarked_C  Embarked_Q  ...  Pclass_1  Pclass_2  Pclass_3  SibSp_1  \\\n",
       "0             0           0  ...         0         0         1        1   \n",
       "1             1           0  ...         1         0         0        1   \n",
       "2             0           0  ...         0         0         1        0   \n",
       "3             0           0  ...         1         0         0        1   \n",
       "4             0           0  ...         0         0         1        0   \n",
       "..          ...         ...  ...       ...       ...       ...      ...   \n",
       "796           0           0  ...         1         0         0        0   \n",
       "797           0           0  ...         0         0         1        0   \n",
       "798           1           0  ...         0         0         1        0   \n",
       "799           0           0  ...         0         0         1        1   \n",
       "800           0           0  ...         0         1         0        0   \n",
       "\n",
       "     SibSp_0  SibSp_2  SibSp_3  SibSp_4  SibSp_6  SibSp_8  \n",
       "0          0        0        0        0        0        0  \n",
       "1          0        0        0        0        0        0  \n",
       "2          1        0        0        0        0        0  \n",
       "3          0        0        0        0        0        0  \n",
       "4          1        0        0        0        0        0  \n",
       "..       ...      ...      ...      ...      ...      ...  \n",
       "796        1        0        0        0        0        0  \n",
       "797        1        0        0        0        0        0  \n",
       "798        1        0        0        0        0        0  \n",
       "799        0        0        0        0        0        0  \n",
       "800        1        0        0        0        0        0  \n",
       "\n",
       "[801 rows x 21 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"./data/train.csv\")\n",
    "train_df = pd.read_csv(\"./data/train.csv\").loc[0:800]\n",
    "train_df = train_df[[\"PassengerId\", \"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Embarked\", \"Parch\", \"Fare\"]]  \n",
    "for index, x in train_df.iterrows():\n",
    "    x[\"SibSp\"] = \"s\" + str(x[\"SibSp\"])\n",
    "\n",
    "train_df = train_df.fillna({\"Embarked\":\"Q\", \"Age\": 0})\n",
    "train_df = pd.get_dummies(train_df) # 独热编码，也可以二值化\n",
    "Pclass_1,Pclass_2,Pclass_3 = [],[],[]\n",
    "\n",
    "for index, line in train_df.iterrows():\n",
    "    if line[\"Pclass\"] == 1.0:\n",
    "        Pclass_1.append(1)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(0)\n",
    "    elif line[\"Pclass\"] == 2.0:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(1)\n",
    "        Pclass_3.append(0)\n",
    "    else:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(1)\n",
    "    \n",
    "        \n",
    "train_df[\"Pclass_1\"], train_df[\"Pclass_2\"], train_df[\"Pclass_3\"] = Pclass_1, Pclass_2, Pclass_3\n",
    "\n",
    "\n",
    "train_df['SibSp_1'] = np.array(train_df['SibSp'] == 1).astype(np.int32)\n",
    "train_df['SibSp_0'] = np.array(train_df['SibSp'] == 0).astype(np.int32)\n",
    "train_df['SibSp_2'] = np.array(train_df['SibSp'] == 2).astype(np.int32)\n",
    "train_df['SibSp_3'] = np.array(train_df['SibSp'] == 3).astype(np.int32)\n",
    "train_df['SibSp_4'] = np.array(train_df['SibSp'] == 4).astype(np.int32)\n",
    "train_df['SibSp_6'] = np.array(train_df['SibSp'] == 6).astype(np.int32)\n",
    "train_df['SibSp_8'] = np.array(train_df['SibSp'] == 8).astype(np.int32)\n",
    "train_df.drop(\"SibSp\", axis=1)\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\"./data/train.csv\").loc[800:]\n",
    "# test_df = pd.read_csv(\"./data/test.csv\")\n",
    "test_df  = test_df[[\"PassengerId\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Embarked\", \"Parch\", \"Fare\"]]\n",
    "test_df = test_df.fillna({\"Embarked\":\"C\", \"Age\": 0})\n",
    "test_df = pd.get_dummies(test_df)\n",
    "Pclass_1,Pclass_2,Pclass_3 = [],[],[]\n",
    "for index, line in test_df.iterrows():\n",
    "    if line[\"Pclass\"] == 1.0:\n",
    "        Pclass_1.append(1)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(0)\n",
    "    elif line[\"Pclass\"] == 2.0:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(1)\n",
    "        Pclass_3.append(0)\n",
    "    else:\n",
    "        Pclass_1.append(0)\n",
    "        Pclass_2.append(0)\n",
    "        Pclass_3.append(1)\n",
    "test_df[\"Pclass_1\"], test_df[\"Pclass_2\"], test_df[\"Pclass_3\"] = Pclass_1, Pclass_2, Pclass_3\n",
    "\n",
    "\n",
    "test_df['SibSp_1'] = np.array(test_df['SibSp'] == 1).astype(np.int32)\n",
    "test_df['SibSp_0'] = np.array(test_df['SibSp'] == 0).astype(np.int32)\n",
    "test_df['SibSp_2'] = np.array(test_df['SibSp'] == 2).astype(np.int32)\n",
    "test_df['SibSp_3'] = np.array(test_df['SibSp'] == 3).astype(np.int32)\n",
    "test_df['SibSp_4'] = np.array(test_df['SibSp'] == 4).astype(np.int32)\n",
    "test_df['SibSp_6'] = np.array(test_df['SibSp'] == 6).astype(np.int32)\n",
    "test_df['SibSp_8'] = np.array(test_df['SibSp'] == 8).astype(np.int32)\n",
    "test_df.drop(\"SibSp\", axis=1)\n",
    "\n",
    "\n",
    "labels = np.array(train_df['Survived'], dtype=np.float32)\n",
    "#labels = np.array(train_df['Survived'], dtype=np.float32)\n",
    "new_labels = []\n",
    "for i in labels:\n",
    "    # 死亡 活着\n",
    "    #  1    0\n",
    "    #  0    1\n",
    "    \n",
    "    if i==1: \n",
    "        new_labels.append([0, 1])\n",
    "    else:\n",
    "        new_labels.append([1, 0])\n",
    "labels = np.array(new_labels)\n",
    "print(labels)\n",
    "train_df = train_df.drop(columns=[\"Survived\"],) \n",
    "train_features = np.array(StandardScaler().fit_transform(train_df), dtype=np.float32)\n",
    "test_features = np.array(StandardScaler().fit_transform(test_df), dtype=np.float32)\n",
    "# test_features = np.array(test_df, dtype=np.float32)\n",
    "# train_features = np.array(train_df, dtype=np.float32)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa6a98",
   "metadata": {},
   "source": [
    "### 定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53d332e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "input_size = train_features.shape[1]\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 7)\n",
    "#         self.hidden1 = nn.Linear(8, 4)\n",
    "#         self.hidden2 = nn.Linear(256, 80)\n",
    "        self.out = nn.Linear(7, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "#         x = F.relu(self.hidden1(x))\n",
    "#         x = F.relu(self.hidden2(x))\n",
    "       # x = F.relu(self.hidden3(x))\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "    \n",
    "net = LinearRegressionModel()   \n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019d74b",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "928e2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "num_epochs = 500\n",
    "train_features = torch.tensor(train_features, dtype=torch.float)\n",
    "labels = torch.tensor(labels, dtype=torch.float)\n",
    "train_ds = TensorDataset(train_features, labels)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True) # MINI-Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50640c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:0.4732544720172882 correct:0 acc:0.0%\n",
      "epoch:25 loss:0.11670279502868652 correct:6 acc:8.955223880597014%\n",
      "epoch:50 loss:0.08039381355047226 correct:7 acc:10.44776119402985%\n",
      "epoch:75 loss:0.13850168883800507 correct:10 acc:14.925373134328357%\n",
      "epoch:100 loss:0.229353129863739 correct:7 acc:10.44776119402985%\n",
      "epoch:125 loss:0.2046557068824768 correct:4 acc:5.970149253731343%\n",
      "epoch:150 loss:0.16859027743339539 correct:6 acc:8.955223880597014%\n",
      "epoch:175 loss:0.05869103968143463 correct:10 acc:14.925373134328357%\n",
      "epoch:200 loss:0.1352815479040146 correct:7 acc:10.44776119402985%\n",
      "epoch:225 loss:0.10665435343980789 correct:9 acc:13.432835820895523%\n",
      "epoch:250 loss:0.23339366912841797 correct:6 acc:8.955223880597014%\n",
      "epoch:275 loss:0.06536366045475006 correct:6 acc:8.955223880597014%\n",
      "epoch:300 loss:0.2167191356420517 correct:10 acc:14.925373134328357%\n",
      "epoch:325 loss:0.12717531621456146 correct:8 acc:11.940298507462686%\n",
      "epoch:350 loss:0.1087428629398346 correct:8 acc:11.940298507462686%\n",
      "epoch:375 loss:0.06028322875499725 correct:11 acc:16.417910447761194%\n",
      "epoch:400 loss:0.20603561401367188 correct:9 acc:13.432835820895523%\n",
      "epoch:425 loss:0.118707574903965 correct:8 acc:11.940298507462686%\n",
      "epoch:450 loss:0.07203903794288635 correct:12 acc:17.91044776119403%\n",
      "epoch:475 loss:0.07822262495756149 correct:7 acc:10.44776119402985%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "best_model_wts = net.state_dict()\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    \n",
    "    total = 0\n",
    "    corrects = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        total +=1\n",
    "        optimizer.zero_grad()\n",
    "        #print(x_batch.shape[1])\n",
    "        outputs = net(x_batch)\n",
    "        answer_ls = list()\n",
    "        for a, b in outputs:\n",
    "            if a>b:\n",
    "                answer_ls.append([1, 0])\n",
    "            else:\n",
    "                answer_ls.append([0, 1])\n",
    "        if torch.tensor(answer_ls, dtype=torch.float).equal(y_batch):\n",
    "            corrects += 1\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    acc = corrects/total*100\n",
    "    if acc > best_acc:\n",
    "        best_model_wts = copy.deepcopy(net.state_dict())\n",
    "        best_acc = acc\n",
    "    if epoch%25==0:\n",
    "        print(\"epoch:{} loss:{} correct:{} acc:{}%\".format(epoch, loss.item(), corrects, corrects/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ab5e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "[1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jerry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54.94505494505495"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#print(\"test features\", test_features)\n",
    "net.load_state_dict(best_model_wts)\n",
    "train_arr = np.array(test_features, dtype=np.float)\n",
    "tensors = torch.tensor(train_arr, dtype=torch.float32)\n",
    "\n",
    "outputs = net(tensors).data.numpy()\n",
    "ans = []\n",
    "for a, b in outputs:\n",
    "    if a>b:\n",
    "        ans.append(1)\n",
    "    else:\n",
    "        ans.append(0)\n",
    "answer = np.array(ans).tolist()\n",
    "\n",
    "        \n",
    "lab = []\n",
    "labels = np.array(labels).tolist()\n",
    "for a, b in labels:\n",
    "    if a==1:\n",
    "        \n",
    "        lab.append(1)\n",
    "    else:\n",
    "        lab.append(0)        \n",
    "length = len(ans)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "print(lab)\n",
    "print(ans)\n",
    "for a in range(length):\n",
    "    if lab[a] == answer[a]:\n",
    "        correct+=1\n",
    "\n",
    "correct/length*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "676dfbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.from_numpy(test_features)\n",
    "predict = net(test_data)\n",
    "outputs = predict.data.numpy()\n",
    "answer_ls = []\n",
    "for a, b in outputs:\n",
    "    if a>b:\n",
    "        answer_ls.append([1, 0])\n",
    "    else:\n",
    "        answer_ls.append([0, 1])\n",
    "lab = []\n",
    "for a, b in answer_ls:\n",
    "    if a==1:\n",
    "        lab.append(0)\n",
    "    else:\n",
    "        lab.append(1)          \n",
    "outputs = np.array(lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "    \"PassengerId\": np.array(range(892, 1310)),\n",
    "    \"Survived\": outputs\n",
    "})\n",
    "dataframe.to_csv(\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c4d01ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jerry\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42980343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8ba8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
